import csv

# 基础URL
base_url = "http://www.bom.gov.au/climate/data/acorn-sat/stations/#/"

# 假设这是你找到的站点编号列表
site_numbers = [
    1019,
    2079,
    3003,
    4032,
    4106,
    5007,
    5098,
    6011,
    7045,
    8296,
    8297,
    8315,
    9021,
    9518,
    9617,
    9789,
    9999,
    10092,
    10286,
    10916,
    10917,
    11003,
    11052,
    12038,
    13017,
    14015,
    1482,
    15135,
    15590,
    15666,
    16001,
    16098,
    17043,
    17126,
    18012,
    18044,
    18192,
    21133,
    22823,
    23000,
    23373,
    26021,
    26026,
    27045,
    27058,
    28004,
    29063,
    29077,
    30124,
    30161,
    31011,
    32040,
    33119,
    34084,
    36007,
    36031,
    37010,
    38003,
    38026,
    39066,
    39083,
    39128,
    40004,
    40043,
    40842,
    42112,
    43109,
    44021,
    45025,
    46012,
    46126,
    48027,
    48245,
    50017,
    52088,
    53115,
    55024,
    56242,
    58012,
    59151,
    60168,
    61078,
    61363,
    63005,
    65070,
    66214,
    67105,
    68072,
    68151,
    69018,
    70351,
    72150,
    72161,
    74258,
    76031,
    78015,
    80023,
    82039,
    84016,
    84145,
    85072,
    85096,
    86338,
    87031,
    90015,
    91293,
    91311,
    92045,
    94029,
    94198,
    94220,
    96003,
]

# 根据站点编号生成URL列表
urls = [f"{base_url}{number}" for number in site_numbers]

# 将URL列表保存到CSV文件
with open("station_urls.csv", "w", newline="", encoding="utf-8") as file:
    writer = csv.writer(file)
    writer.writerow(["URL"])  # 写入标题行
    for url in urls:
        writer.writerow([url])  # 写入每个URL

print("URLs have been saved to station_urls.csv.")
